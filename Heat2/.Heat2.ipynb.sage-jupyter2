{"backend_state":"init","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-d1675077-a27c-49f5-b710-5c06f59c1082.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"nbgrader":{"__altered":false,"__hash":-525552843,"_root":{"entries":[["size",6],["_root",{"entries":[["size",6],["_root",{"entries":[["size",1],["_root",{"entries":[["cocalc_minimal_stubs",true]],"ownerID":{}}],["__ownerID",null],["__hash",912286151],["__altered",false],["cocalc_minimal_stubs",true]],"ownerID":{}}],["__ownerID",null],["__hash",853781301],["__altered",false],["cocalc_minimal_stubs",false]],"ownerID":{}}],["__ownerID",null],["__hash",-84714022],["__altered",false],["cocalc_minimal_stubs",false]],"ownerID":{}},"cocalc_minimal_stubs":false,"size":6}},"trust":true,"type":"settings"}
{"cell_type":"code","collapsed":true,"exec_count":59,"id":"35f9c0","input":"from nose.tools import assert_equal\nassert_equal(missing_years(get_table(\"Albany\"))[2], 1966)\nassert_equal(len(missing_years(get_table(\"Albany\"))), 40)\nassert_equal(len(missing_years(get_table(\"Perth\"))), 2)\nprint(\"So far, so good.\")\n","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"missing_years","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n  73  74  75  76  77  78  79  80  81  82  83  84 123 124 125 126 127 128\n 129 130 131 132 133 134 135 136 137 138 139 140 141]\n[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n  73  74  75  76  77  78  79  80  81  82  83  84 123 124 125 126 127 128\n 129 130 131 132 133 134 135 136 137 138 139 140 141]\n[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n 73 74 75 76 77]\nSo far, so good.\n"}},"pos":80,"type":"cell"}
{"cell_type":"code","collapsed":true,"exec_count":60,"id":"7666a7","input":"def augmented (table):\n    fullyear=np.arange(table[0,0],table[-1,0]+1,dtype=int)\n    get_temp=clean(table)[:,-1]\n\n    #use the cleaned table to get an array of the years that have valid data\n    #keep row that dont have null value for annual average\n    remove_nullmask=np.logical_not(np.isnan(table[:,-1]))\n    get_row=table[remove_nullmask]\n    #print(get_row)\n\n    #keeps rows that have a calculated mean temperature within 0.15 of the reported annual average\n    calculated_average=np.mean(get_row[:,1:-1],axis=1)\n    validtemp_mask=np.isclose(calculated_average,get_row[:,-1],rtol=0.15)\n\n    get_validyear=get_row[validtemp_mask][:,0].astype('int32')\n    #print(get_validyear)\n\n    #index for valid year\n    get_index=get_validyear[:]-fullyear[0]\n\n    arr_nan=np.full(fullyear.size,np.nan,dtype= np.float64) #create full year nan array\n    mask=np.full(fullyear.size,False,dtype=bool) #array of false in fullyear size\n    mask[get_index]=True\n    arr_nan[mask]=get_temp\n    return fullyear,arr_nan\n\n\n\naugmented(get_table(\"Albany\"))","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"8c8dc416aed2fa46ec6c62edd10b19c5","grade":false,"grade_id":"7666a7","locked":false,"schema_version":3,"solution":true,"task":false}},"output":{"0":{"data":{"text/plain":"(array([1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890,\n        1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901,\n        1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912,\n        1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923,\n        1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934,\n        1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945,\n        1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956,\n        1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967,\n        1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978,\n        1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989,\n        1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,\n        2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011,\n        2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]),\n array([18.2, 18.2, 17.8, 17.8, 17.9, 17.8, 17.6, 17.3, 18.4, 17.1, 17. ,\n        18.3, 18.8, 18.9, 19.8, 19.6, 20.1, 19.6, 20.1, 19.7, 19. , 19.8,\n        19.4, 18.8, 19.7, 18.9, 19.7, 20.1, 19.7, 20. , 20.2, 20. , 19.9,\n        19.5, 19.8, 20. , 20. , 19.5, 20.8, 20.3, 20.6, 21. , 19.9, 20. ,\n        20. , 19.5, 19.2, 19.4, 19.3, 18.9, 20.4, 19.3, 19.8, 20.3, 20.3,\n        19.4, 19.8, 20. ,  nan, 19.9, 20.4, 20. , 19.6, 19.1, 19.6, 19.7,\n        19.5, 19.4, 19.9, 20.1, 20. , 19.3, 19.3, 19.4, 19.7, 19. , 19.3,\n        20.2, 19.8, 20.1, 18.8, 20.3, 20.1, 20.1, 19.1,  nan,  nan,  nan,\n         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n         nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n         nan,  nan, 19.8, 19.6, 19.4, 19.6, 19.7, 19.5, 19.6, 19.8, 20.4,\n        20.8, 20.3, 20.3, 20.3, 19.4, 19.7, 19.7, 19.9, 20.1, 19.7,  nan]))"},"exec_count":60,"output_type":"execute_result"}},"pos":82,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"7a398c","input":"table[0]","pos":79,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"814c97","input":"import matplotlib.pyplot as plt\n","pos":86,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9269be","input":"","pos":3,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"991cb4","input":"assert_equal(augmented(get_table(\"Albany\"))[1][84], 19.1)\nassert_equal(np.isnan(augmented(get_table(\"Albany\"))[1][85]), True)\nassert_equal(np.isnan(augmented(get_table(\"Albany\"))[1][86]), True)\nprint(\"So far, so good.\")\n","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"augmented","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"pos":83,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"db7c58","input":"","pos":70,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"e0c8fc","input":"get_table('Albany')","pos":78,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"24b53d","input":"np.mean(get_town('Albany')[0][1:-1])==get_town('Albany')[0][-1]","output":{"0":{"data":{"text/plain":"True"},"exec_count":10,"output_type":"execute_result"}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"057a37","input":"#Returns a boolean array where two arrays are element-wise equal within a tolerance.\nnp.isclose(np.mean(get_town('Albany')[0][1:-1]),get_town('Albany')[0][-1])","output":{"0":{"data":{"text/plain":"True"},"exec_count":11,"output_type":"execute_result"}},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"46a095","input":"\n#Select all of the monthly temperature data into an array (that is, all columns except the year and the average). Check the shape is as you would expect.\nget_town('Albany')[:,1:-1]\n\n\n","output":{"0":{"data":{"text/plain":"array([[22.1, 22.8, 20.6, ..., 16.2, 18. , 20.8],\n       [20.1, 22.2, 22.2, ..., 16.1, 18.7, 20.7],\n       [20.2, 22.1, 20.1, ..., 17.3, 17.8, 20.8],\n       ...,\n       [22.2, 23.4, 23.1, ..., 19.4, 20.5, 21.1],\n       [22.8, 21.9, 23.6, ..., 18. , 18.8, 21.3],\n       [22.4, 23.6, 22.6, ...,  nan,  nan,  nan]])"},"exec_count":12,"output_type":"execute_result"}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"184b5c","input":"#Use ndarray.mean() or numpy.mean() with the axis argument to get an array of the means for all years, rounded to 1 decimal place. Check the shape (to ensure you used the right axis).\nget_ave=np.round(np.mean(get_town('Albany')[:,1:-1],axis=1),1)\nget_ave","output":{"0":{"data":{"text/plain":"array([18.2, 18.2, 17.8, 17.8, 17.9, 17.8, 17.6, 17.3, 18.4, 17.1, 17. ,\n       18.3, 18.8, 18.9, 19.8, 19.6, 20.1, 19.6, 20.1, 19.7, 19. , 19.8,\n       19.4, 18.8, 19.7, 19. , 19.7, 20.1, 19.7, 20. , 20.2, 20. , 19.9,\n       19.5, 19.8, 20. , 20. , 19.5, 20.8, 20.3, 20.7, 21. , 19.9, 20. ,\n       20. , 19.5, 19.2, 19.4, 19.3, 18.8, 20.4, 19.3, 19.8, 20.3, 20.3,\n       19.4, 19.8, 20. ,  nan, 19.9, 20.4, 20. , 19.6, 19.1, 19.6, 19.7,\n       19.5, 19.4, 20. , 20.1, 20. , 19.3, 19.3, 19.4, 19.7, 19. , 19.3,\n       20.2, 19.8, 20.1, 18.8, 20.3, 20.1, 20.1, 19.1,  nan,  nan, 19.8,\n       19.6, 19.4, 19.6, 19.7, 19.4, 19.6, 19.8, 20.4, 20.8, 20.3, 20.3,\n       20.3, 19.3, 19.7, 19.7, 19.9, 20.1, 19.7,  nan])"},"exec_count":13,"output_type":"execute_result"}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"4f4990","input":"#Create a boolean array called mismatch of all those years where the stated annual average is not equal to your calculated average. Check the shape.\n#mismatch=(get_ave!=get_town('Albany')[:,-1])\n#mismatch\n","pos":21,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"7f7bbe","input":"np.not_equal(get_ave,get_town('Albany')[:,-1])","output":{"0":{"data":{"text/plain":"array([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True,  True, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False,  True])"},"exec_count":15,"output_type":"execute_result"}},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"87b275","input":"correct_data=np.isclose(get_ave,get_town('Albany')[:,-1])\ncorrect_data","output":{"0":{"data":{"text/plain":"array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True, False,  True,  True,  True,  True,\n        True,  True,  True,  True, False,  True,  True,  True,  True,\n        True,  True,  True,  True, False,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True, False, False,  True,  True,  True,\n        True,  True, False,  True,  True,  True,  True,  True,  True,\n        True, False,  True,  True,  True,  True,  True, False])"},"exec_count":16,"output_type":"execute_result"}},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"8a2355","input":"#np.logical_not for invert\nmismatch=np.logical_not(np.isclose(get_ave,get_town('Albany')[:,-1]))\nmismatch","output":{"0":{"data":{"text/plain":"array([False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True,  True, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False,  True])"},"exec_count":17,"output_type":"execute_result"}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":18,"id":"d17840","input":"np.count_nonzero(mismatch) #count true","output":{"0":{"data":{"text/plain":"10"},"exec_count":18,"output_type":"execute_result"}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"17ab08","input":"np.any(get_ave)","output":{"0":{"data":{"text/plain":"True"},"exec_count":19,"output_type":"execute_result"}},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"c783c7","input":"MONTHLY_TEMPERATURE = \"IDCJAC0002\"\nPER_LINE = 12\n\nSTATIONS = {\"Albany\": \"009500\",\n            \"Perth\": \"009021\",\n            \"Broome\": \"003003\",\n            \"Geraldton\": \"008050\"\n           }","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":false,"grade_id":"c783c7","locked":true,"schema_version":3,"solution":false,"task":false}},"pos":2,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"360803","input":"#to select all the rows in the Albany data where the averages don't match.\n\nget_town('Albany')[mismatch]","output":{"0":{"data":{"text/plain":"array([[1905. ,   22.8,   21.6,   20.9,   21.1,   18.2,   16.2,   15.9,\n          15. ,   15.7,   17.3,   20.2,   22.5,   18.9],\n       [1920. ,   25.3,   24.2,   23.8,   22.8,   19. ,   16.2,   15.8,\n          15.8,   18.2,   20.8,   22.5,   23.4,   20.6],\n       [1929. ,   21.9,   22.5,   20.5,   20.1,   17.7,   15.5,   15.2,\n          15.2,   17.7,   18.1,   20.1,   21.7,   18.9],\n       [1938. ,   22.4,   21.9,   22.2,   19.9,   18.5,   16.1,   16. ,\n          16.9,   18. ,   19.7,   21.4,    nan,    nan],\n       [1948. ,   23.8,   23.8,   23.7,   20.6,   20.1,   17.3,   15.9,\n          17.4,   17.6,   18.5,   19.7,   21. ,   19.9],\n       [1965. ,   24.4,   23.6,   23.1,   22.3,    nan,    nan,    nan,\n           nan,    nan,    nan,    nan,    nan,    nan],\n       [2002. ,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n           nan,   17.5,   19. ,   20.2,   21.3,    nan],\n       [2008. ,   21.8,   22.8,   21.9,   21.3,   19.9,   17.9,   15.6,\n          16.6,   17.9,   18.4,   18.6,   20.7,   19.5],\n       [2016. ,   22.7,   23.4,   22.6,   20.6,   18.6,   16.7,   16.2,\n          16.1,   15.9,   18. ,   20.6,   20.8,   19.4],\n       [2022. ,   22.4,   23.6,   22.6,   21.4,   19. ,   17.6,   17.2,\n          15.9,    nan,    nan,    nan,    nan,    nan]])"},"exec_count":20,"output_type":"execute_result"}},"pos":29,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"b90abc","input":"#extract year and annual average column\nyear_and_av=[True, False, False, False, False, False, False, False, False, False, False, False, False, True]#mask for taking first and last column\n\nprint(get_town('Albany')[mismatch][:,year_and_av])","output":{"0":{"name":"stdout","output_type":"stream","text":"[[1905.    18.9]\n [1920.    20.6]\n [1929.    18.9]\n [1938.     nan]\n [1948.    19.9]\n [1965.     nan]\n [2002.     nan]\n [2008.    19.5]\n [2016.    19.4]\n [2022.     nan]]\n"}},"pos":30,"type":"cell"}
{"cell_type":"code","exec_count":22,"id":"327d71","input":"first_year = get_town('Albany')[0,:]         # select a 1-D array of the first year\nfirst_year\nquarters = np.array([3,6,9,12])  # specify an array of indices for March, June, September, December\nquarters\nprint(first_year[quarters])\n","output":{"0":{"name":"stdout","output_type":"stream","text":"[20.6 14.7 16.2 20.8]\n"}},"pos":32,"type":"cell"}
{"cell_type":"code","exec_count":23,"id":"b3ae6b","input":"get_town('Albany')","output":{"0":{"data":{"text/plain":"array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n       [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n       [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n       ...,\n       [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n       [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7],\n       [2022. ,   22.4,   23.6, ...,    nan,    nan,    nan]])"},"exec_count":23,"output_type":"execute_result"}},"pos":35,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"93f208","input":"from nose.tools import assert_equal, assert_true\n(average, years) = hot_years(\"Albany\")\nassert_true(np.isclose(average%0.2,0.12912621359223414))\nassert_equal(years.shape, (63,2))\nassert_true(np.isclose(years[-1,0]-years[0,0],127))\nassert_true(np.isclose(years[-1,1]-years[0,1],-0.1))\n\n(average, years) = hot_years(\"Geraldton\") # will be tested next!\nprint(\"So far, so good. Continue with your own testing.\")\n","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"hot_years","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"So far, so good. Continue with your own testing.\n"}},"pos":37,"type":"cell"}
{"cell_type":"code","exec_count":26,"id":"db79a9","input":"#extracting columns is to stack them in a new array","pos":39,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"71d7ed","input":"print(np.stack((get_town('Albany')[mismatch,0],get_town('Albany')[mismatch,13])))\n","output":{"0":{"name":"stdout","output_type":"stream","text":"[[1905.  1920.  1929.  1938.  1948.  1965.  2002.  2008.  2016.  2022. ]\n [  18.9   20.6   18.9    nan   19.9    nan    nan   19.5   19.4    nan]]\n"}},"pos":40,"type":"cell"}
{"cell_type":"code","exec_count":28,"id":"bf695b","input":"print(np.transpose(np.stack((get_town('Albany')[mismatch,0],get_town('Albany')[mismatch,13]))))","output":{"0":{"name":"stdout","output_type":"stream","text":"[[1905.    18.9]\n [1920.    20.6]\n [1929.    18.9]\n [1938.     nan]\n [1948.    19.9]\n [1965.     nan]\n [2002.     nan]\n [2008.    19.5]\n [2016.    19.4]\n [2022.     nan]]\n"}},"pos":41,"type":"cell"}
{"cell_type":"code","exec_count":29,"id":"1741e9","input":"def get_temperatures(stations, quiet=True):\n    towns=sorted(stations)\n    tables=[]\n    for x in towns:\n        tem_arr=np.genfromtxt(fname=temperature_file(x),skip_header=1,delimiter=\",\",usecols=range(2,16))\n        tables.append(tem_arr)\n\n    if quiet:\n        return(towns,tables);\n\n    else:\n        get_temps()\n        return(towns,tables)\n\n\nget_temperatures(STATIONS, quiet=True)","output":{"0":{"data":{"text/plain":"(['Albany', 'Broome', 'Geraldton', 'Perth'],\n [array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n         [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n         [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n         ...,\n         [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n         [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7],\n         [2022. ,   22.4,   23.6, ...,    nan,    nan,    nan]]),\n  array([[1939. ,    nan,    nan, ...,   33. ,   34.7,    nan],\n         [1940. ,   31.8,   33.1, ...,   35.4,   34.4,   32.3],\n         [1941. ,   33.5,   34.9, ...,   33.2,   34.7,   31.8],\n         ...,\n         [2020. ,   33.3,   33.7, ...,   34.6,   33.3,   32.9],\n         [2021. ,   35. ,   33.1, ...,   34.7,   34.6,   32.9],\n         [2022. ,   33.7,   34.3, ...,    nan,    nan,    nan]]),\n  array([[1880. ,   31.3,   26.8, ...,   23.7,   25.6,   23.2],\n         [1881. ,   26.9,   28.9, ...,   24.4,   28.9,   24.1],\n         [1882. ,   26.6,   28.8, ...,   23.6,   26.3,   22.6],\n         ...,\n         [1951. ,   26.6,   29.3, ...,   24.4,   26.4,   24.2],\n         [1952. ,   29.3,   31.5, ...,   23.8,   27.7,   25.2],\n         [1953. ,   31. ,   29.1, ...,    nan,    nan,    nan]]),\n  array([[1944. ,    nan,    nan, ...,   26.8,   25.5,    nan],\n         [1945. ,   31.5,   32.1, ...,   25.8,   28.4,   24.4],\n         [1946. ,   28.2,   29.8, ...,   24.4,   27.4,   23.6],\n         ...,\n         [2020. ,   31.6,   33. , ...,   25. ,   32.4,   25.7],\n         [2021. ,   33.6,   30.8, ...,   26.8,   32.5,   25.3],\n         [2022. ,   34.6,   35.1, ...,    nan,    nan,    nan]])])"},"exec_count":29,"output_type":"execute_result"}},"pos":43,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"81b0f9","input":"from pathlib import Path\nimport numpy as np","pos":5,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"701589","input":"towns,tables=get_temperatures(STATIONS, quiet=True)\ntowns.index('Albany')","output":{"0":{"data":{"text/plain":"0"},"exec_count":30,"output_type":"execute_result"}},"pos":44,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"b1c257","input":"a = np.array([2, 3, 4, 5, 6, 45, 67, 34])\nnp.where(a==67)","output":{"0":{"data":{"text/plain":"(array([6]),)"},"exec_count":31,"output_type":"execute_result"}},"pos":45,"type":"cell"}
{"cell_type":"code","exec_count":32,"id":"8af94d","input":"tables","output":{"0":{"data":{"text/plain":"[array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n        [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n        [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n        ...,\n        [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n        [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7],\n        [2022. ,   22.4,   23.6, ...,    nan,    nan,    nan]]),\n array([[1939. ,    nan,    nan, ...,   33. ,   34.7,    nan],\n        [1940. ,   31.8,   33.1, ...,   35.4,   34.4,   32.3],\n        [1941. ,   33.5,   34.9, ...,   33.2,   34.7,   31.8],\n        ...,\n        [2020. ,   33.3,   33.7, ...,   34.6,   33.3,   32.9],\n        [2021. ,   35. ,   33.1, ...,   34.7,   34.6,   32.9],\n        [2022. ,   33.7,   34.3, ...,    nan,    nan,    nan]]),\n array([[1880. ,   31.3,   26.8, ...,   23.7,   25.6,   23.2],\n        [1881. ,   26.9,   28.9, ...,   24.4,   28.9,   24.1],\n        [1882. ,   26.6,   28.8, ...,   23.6,   26.3,   22.6],\n        ...,\n        [1951. ,   26.6,   29.3, ...,   24.4,   26.4,   24.2],\n        [1952. ,   29.3,   31.5, ...,   23.8,   27.7,   25.2],\n        [1953. ,   31. ,   29.1, ...,    nan,    nan,    nan]]),\n array([[1944. ,    nan,    nan, ...,   26.8,   25.5,    nan],\n        [1945. ,   31.5,   32.1, ...,   25.8,   28.4,   24.4],\n        [1946. ,   28.2,   29.8, ...,   24.4,   27.4,   23.6],\n        ...,\n        [2020. ,   31.6,   33. , ...,   25. ,   32.4,   25.7],\n        [2021. ,   33.6,   30.8, ...,   26.8,   32.5,   25.3],\n        [2022. ,   34.6,   35.1, ...,    nan,    nan,    nan]])]"},"exec_count":32,"output_type":"execute_result"}},"pos":46,"type":"cell"}
{"cell_type":"code","exec_count":33,"id":"e72f45","input":"(albany, broome, perth) = (tables[towns.index(\"Albany\")], tables[towns.index(\"Broome\")], tables[towns.index(\"Perth\")])\nall_years = np.hstack((albany[:,0], broome[:,0], perth[:,0]))\nprint(all_years.shape)\nprint(all_years)","output":{"0":{"name":"stdout","output_type":"stream","text":"(270,)\n[1880. 1881. 1882. 1883. 1884. 1885. 1886. 1887. 1888. 1889. 1890. 1891.\n 1892. 1893. 1894. 1895. 1896. 1897. 1898. 1899. 1900. 1901. 1902. 1903.\n 1904. 1905. 1906. 1907. 1908. 1909. 1910. 1911. 1912. 1913. 1914. 1915.\n 1916. 1917. 1918. 1919. 1920. 1921. 1922. 1923. 1924. 1925. 1926. 1927.\n 1928. 1929. 1930. 1931. 1932. 1933. 1934. 1935. 1936. 1937. 1938. 1939.\n 1940. 1941. 1942. 1943. 1944. 1945. 1946. 1947. 1948. 1949. 1950. 1951.\n 1952. 1953. 1954. 1955. 1956. 1957. 1958. 1959. 1960. 1961. 1962. 1963.\n 1964. 1965. 2002. 2003. 2004. 2005. 2006. 2007. 2008. 2009. 2010. 2011.\n 2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 1939.\n 1940. 1941. 1942. 1943. 1944. 1945. 1946. 1947. 1948. 1949. 1950. 1951.\n 1952. 1953. 1954. 1955. 1956. 1957. 1958. 1959. 1960. 1961. 1962. 1963.\n 1964. 1965. 1966. 1967. 1968. 1969. 1970. 1971. 1972. 1973. 1974. 1975.\n 1976. 1977. 1978. 1979. 1980. 1981. 1982. 1983. 1984. 1985. 1986. 1987.\n 1988. 1989. 1990. 1991. 1992. 1993. 1994. 1995. 1996. 1997. 1998. 1999.\n 2000. 2001. 2002. 2003. 2004. 2005. 2006. 2007. 2008. 2009. 2010. 2011.\n 2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 1944.\n 1945. 1946. 1947. 1948. 1949. 1950. 1951. 1952. 1953. 1954. 1955. 1956.\n 1957. 1958. 1959. 1960. 1961. 1962. 1963. 1964. 1965. 1966. 1967. 1968.\n 1969. 1970. 1971. 1972. 1973. 1974. 1975. 1976. 1977. 1978. 1979. 1980.\n 1981. 1982. 1983. 1984. 1985. 1986. 1987. 1988. 1989. 1990. 1991. 1992.\n 1993. 1994. 1995. 1996. 1997. 1998. 1999. 2000. 2001. 2002. 2003. 2004.\n 2005. 2006. 2007. 2008. 2009. 2010. 2011. 2012. 2013. 2014. 2015. 2016.\n 2017. 2018. 2019. 2020. 2021. 2022.]\n"}},"pos":47,"type":"cell"}
{"cell_type":"code","exec_count":34,"id":"9f374c","input":"(get_temperatures(STATIONS,quiet=True)[1])","output":{"0":{"data":{"text/plain":"[array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n        [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n        [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n        ...,\n        [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n        [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7],\n        [2022. ,   22.4,   23.6, ...,    nan,    nan,    nan]]),\n array([[1939. ,    nan,    nan, ...,   33. ,   34.7,    nan],\n        [1940. ,   31.8,   33.1, ...,   35.4,   34.4,   32.3],\n        [1941. ,   33.5,   34.9, ...,   33.2,   34.7,   31.8],\n        ...,\n        [2020. ,   33.3,   33.7, ...,   34.6,   33.3,   32.9],\n        [2021. ,   35. ,   33.1, ...,   34.7,   34.6,   32.9],\n        [2022. ,   33.7,   34.3, ...,    nan,    nan,    nan]]),\n array([[1880. ,   31.3,   26.8, ...,   23.7,   25.6,   23.2],\n        [1881. ,   26.9,   28.9, ...,   24.4,   28.9,   24.1],\n        [1882. ,   26.6,   28.8, ...,   23.6,   26.3,   22.6],\n        ...,\n        [1951. ,   26.6,   29.3, ...,   24.4,   26.4,   24.2],\n        [1952. ,   29.3,   31.5, ...,   23.8,   27.7,   25.2],\n        [1953. ,   31. ,   29.1, ...,    nan,    nan,    nan]]),\n array([[1944. ,    nan,    nan, ...,   26.8,   25.5,    nan],\n        [1945. ,   31.5,   32.1, ...,   25.8,   28.4,   24.4],\n        [1946. ,   28.2,   29.8, ...,   24.4,   27.4,   23.6],\n        ...,\n        [2020. ,   31.6,   33. , ...,   25. ,   32.4,   25.7],\n        [2021. ,   33.6,   30.8, ...,   26.8,   32.5,   25.3],\n        [2022. ,   34.6,   35.1, ...,    nan,    nan,    nan]])]"},"exec_count":34,"output_type":"execute_result"}},"pos":49,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":35,"id":"440ac6","input":"get_town('Albany')","output":{"0":{"data":{"text/plain":"array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n       [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n       [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n       ...,\n       [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n       [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7],\n       [2022. ,   22.4,   23.6, ...,    nan,    nan,    nan]])"},"exec_count":35,"output_type":"execute_result"}},"pos":50,"type":"cell"}
{"cell_type":"code","exec_count":38,"id":"f8377d","input":"towns,table=get_temperatures(STATIONS, quiet=True)\ntable","output":{"0":{"data":{"text/plain":"[array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n        [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n        [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n        ...,\n        [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n        [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7],\n        [2022. ,   22.4,   23.6, ...,    nan,    nan,    nan]]),\n array([[1939. ,    nan,    nan, ...,   33. ,   34.7,    nan],\n        [1940. ,   31.8,   33.1, ...,   35.4,   34.4,   32.3],\n        [1941. ,   33.5,   34.9, ...,   33.2,   34.7,   31.8],\n        ...,\n        [2020. ,   33.3,   33.7, ...,   34.6,   33.3,   32.9],\n        [2021. ,   35. ,   33.1, ...,   34.7,   34.6,   32.9],\n        [2022. ,   33.7,   34.3, ...,    nan,    nan,    nan]]),\n array([[1880. ,   31.3,   26.8, ...,   23.7,   25.6,   23.2],\n        [1881. ,   26.9,   28.9, ...,   24.4,   28.9,   24.1],\n        [1882. ,   26.6,   28.8, ...,   23.6,   26.3,   22.6],\n        ...,\n        [1951. ,   26.6,   29.3, ...,   24.4,   26.4,   24.2],\n        [1952. ,   29.3,   31.5, ...,   23.8,   27.7,   25.2],\n        [1953. ,   31. ,   29.1, ...,    nan,    nan,    nan]]),\n array([[1944. ,    nan,    nan, ...,   26.8,   25.5,    nan],\n        [1945. ,   31.5,   32.1, ...,   25.8,   28.4,   24.4],\n        [1946. ,   28.2,   29.8, ...,   24.4,   27.4,   23.6],\n        ...,\n        [2020. ,   31.6,   33. , ...,   25. ,   32.4,   25.7],\n        [2021. ,   33.6,   30.8, ...,   26.8,   32.5,   25.3],\n        [2022. ,   34.6,   35.1, ...,    nan,    nan,    nan]])]"},"exec_count":38,"output_type":"execute_result"}},"pos":56,"type":"cell"}
{"cell_type":"code","exec_count":39,"id":"72f392","input":"for data in table:\n    print(data[:,0])","output":{"0":{"name":"stdout","output_type":"stream","text":"[1880. 1881. 1882. 1883. 1884. 1885. 1886. 1887. 1888. 1889. 1890. 1891.\n 1892. 1893. 1894. 1895. 1896. 1897. 1898. 1899. 1900. 1901. 1902. 1903.\n 1904. 1905. 1906. 1907. 1908. 1909. 1910. 1911. 1912. 1913. 1914. 1915.\n 1916. 1917. 1918. 1919. 1920. 1921. 1922. 1923. 1924. 1925. 1926. 1927.\n 1928. 1929. 1930. 1931. 1932. 1933. 1934. 1935. 1936. 1937. 1938. 1939.\n 1940. 1941. 1942. 1943. 1944. 1945. 1946. 1947. 1948. 1949. 1950. 1951.\n 1952. 1953. 1954. 1955. 1956. 1957. 1958. 1959. 1960. 1961. 1962. 1963.\n 1964. 1965. 2002. 2003. 2004. 2005. 2006. 2007. 2008. 2009. 2010. 2011.\n 2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022.]\n[1939. 1940. 1941. 1942. 1943. 1944. 1945. 1946. 1947. 1948. 1949. 1950.\n 1951. 1952. 1953. 1954. 1955. 1956. 1957. 1958. 1959. 1960. 1961. 1962.\n 1963. 1964. 1965. 1966. 1967. 1968. 1969. 1970. 1971. 1972. 1973. 1974.\n 1975. 1976. 1977. 1978. 1979. 1980. 1981. 1982. 1983. 1984. 1985. 1986.\n 1987. 1988. 1989. 1990. 1991. 1992. 1993. 1994. 1995. 1996. 1997. 1998.\n 1999. 2000. 2001. 2002. 2003. 2004. 2005. 2006. 2007. 2008. 2009. 2010.\n 2011. 2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022.]\n[1880. 1881. 1882. 1883. 1885. 1886. 1887. 1888. 1889. 1890. 1891. 1892.\n 1893. 1894. 1895. 1896. 1897. 1898. 1899. 1900. 1901. 1902. 1903. 1904.\n 1905. 1906. 1907. 1908. 1909. 1910. 1911. 1912. 1913. 1914. 1915. 1916.\n 1917. 1918. 1919. 1920. 1921. 1922. 1923. 1924. 1925. 1926. 1927. 1928.\n 1929. 1930. 1931. 1932. 1933. 1934. 1935. 1936. 1937. 1938. 1939. 1940.\n 1941. 1942. 1943. 1944. 1945. 1946. 1947. 1948. 1949. 1950. 1951. 1952.\n 1953.]\n[1944. 1945. 1946. 1947. 1948. 1949. 1950. 1951. 1952. 1953. 1954. 1955.\n 1956. 1957. 1958. 1959. 1960. 1961. 1962. 1963. 1964. 1965. 1966. 1967.\n 1968. 1969. 1970. 1971. 1972. 1973. 1974. 1975. 1976. 1977. 1978. 1979.\n 1980. 1981. 1982. 1983. 1984. 1985. 1986. 1987. 1988. 1989. 1990. 1991.\n 1992. 1993. 1994. 1995. 1996. 1997. 1998. 1999. 2000. 2001. 2002. 2003.\n 2004. 2005. 2006. 2007. 2008. 2009. 2010. 2011. 2012. 2013. 2014. 2015.\n 2016. 2017. 2018. 2019. 2020. 2021. 2022.]\n"}},"pos":58,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"80272b","input":"def temperature_file (town):\n    #get directory name and store it in a variable\n    #dir_name=\"{}_{}_Data{}.csv\".format(MONTHLY_TEMPERATURE,STATIONS[town],PER_LINE)\n    dir_path=Path(\"{}_{}/{}_{}_Data{}.csv\".format(MONTHLY_TEMPERATURE,STATIONS[town],MONTHLY_TEMPERATURE,STATIONS[town],PER_LINE))\n    return dir_path\n\ntemperature_file('Broome')","output":{"0":{"data":{"text/plain":"PosixPath('IDCJAC0002_003003/IDCJAC0002_003003_Data12.csv')"},"exec_count":4,"output_type":"execute_result"}},"pos":6,"type":"cell"}
{"cell_type":"code","exec_count":40,"id":"1a4b6e","input":"def clean(table):\n    #insert one of the town array\n    remove_nullmask=np.logical_not(np.isnan(table[:,-1]))#keep row that dont have null value for annual average\n    get_row=table[remove_nullmask]\n    #mask that keeps all the rows that have a calculated mean temperature within 0.15 of the reported annual average\n    calculated_average=np.mean(get_row[:,1:-1],axis=1)\n    validtemp_mask=np.isclose(calculated_average,get_row[:,-1],rtol=0.15) #check if rtol is correct /no to round to 1decimal ????????\n    return get_row[validtemp_mask]\nclean(table[0])","output":{"0":{"data":{"text/plain":"array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n       [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n       [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n       ...,\n       [2019. ,   22.2,   22.2, ...,   19.4,   23.5,   19.9],\n       [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n       [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7]])"},"exec_count":40,"output_type":"execute_result"}},"pos":59,"type":"cell"}
{"cell_type":"code","exec_count":41,"id":"981987","input":"np.isclose(22.15555,22,rtol=0.15)","output":{"0":{"data":{"text/plain":"True"},"exec_count":41,"output_type":"execute_result"}},"pos":60,"type":"cell"}
{"cell_type":"code","exec_count":42,"id":"6bbdbf","input":"def clean_all (tables):\n    cleaned_data=[]\n    for each_town in tables:\n         cleaned_data.append(clean(each_town))\n    return(cleaned_data)# takes a list of tables and returns a list of cleaned tables.\n\nclean_all(table)","metadata":{"deletable":false,"nbgrader":{"checksum":"ca0dd399748c2b86bd1a67b849167976","grade":false,"grade_id":"6bbdbf","locked":false,"schema_version":3,"solution":true,"task":false}},"output":{"0":{"data":{"text/plain":"[array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n        [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n        [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n        ...,\n        [2019. ,   22.2,   22.2, ...,   19.4,   23.5,   19.9],\n        [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n        [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7]]),\n array([[1940. ,   31.8,   33.1, ...,   35.4,   34.4,   32.3],\n        [1941. ,   33.5,   34.9, ...,   33.2,   34.7,   31.8],\n        [1942. ,   31.6,   31.3, ...,   34.2,   33.5,   31.8],\n        ...,\n        [2019. ,   34. ,   33.4, ...,   36.9,   36.7,   33.7],\n        [2020. ,   33.3,   33.7, ...,   34.6,   33.3,   32.9],\n        [2021. ,   35. ,   33.1, ...,   34.7,   34.6,   32.9]]),\n array([[1880. ,   31.3,   26.8,   26.4,   23.9,   21.8,   18.8,   18.7,\n           19.1,   21.4,   20.8,   23.7,   25.6,   23.2],\n        [1881. ,   26.9,   28.9,   29.7,   25.1,   21.5,   18.9,   20. ,\n           20.4,   21.6,   22.7,   24.4,   28.9,   24.1],\n        [1882. ,   26.6,   28.8,   25.7,   23.2,   20.9,   18.2,   17.8,\n           18.2,   19.8,   22.4,   23.6,   26.3,   22.6],\n        [1883. ,   26.4,   31.9,   25.7,   26.1,   22.9,   20.6,   18.8,\n           18.8,   20.4,   22.9,   24.1,   25.7,   23.7],\n        [1885. ,   27.1,   28. ,   28.1,   25.2,   21.1,   20.4,   19.4,\n           19.4,   20.4,   23.4,   29.1,   31.7,   24.4],\n        [1886. ,   32.2,   34.6,   30.7,   28. ,   26.1,   22.1,   22.3,\n           20.7,   22.3,   23.6,   26.6,   32.2,   26.8],\n        [1887. ,   30.9,   33.2,   32.4,   27.8,   24.2,   21.2,   19.6,\n           19.9,   20.3,   23. ,   27.3,   28.8,   25.7],\n        [1888. ,   29.3,   28.8,   33.8,   25.2,   22.7,   21.1,   19.1,\n           19.9,   21.8,   24.8,   26.9,   28.2,   25.1],\n        [1889. ,   29.4,   27.2,   30.3,   27.6,   22.4,   19.8,   20.3,\n           20.1,   21.6,   22.4,   23.7,   26.9,   24.3],\n        [1890. ,   29.2,   27.8,   28.1,   28.1,   22.4,   19.3,   18.1,\n           19.4,   20.2,   21.7,   26.2,   28.1,   24.1],\n        [1892. ,   28.1,   32.3,   27.2,   26.8,   23.4,   19.7,   19.7,\n           19.5,   21.7,   21.9,   24.1,   26.5,   24.2],\n        [1893. ,   30.3,   29.1,   28.5,   24.4,   21.6,   19.3,   19.7,\n           20.4,   21.8,   24.2,   25.5,   26.4,   24.3],\n        [1894. ,   32.3,   32.9,   29.1,   26.7,   23.9,   21.6,   20.6,\n           20.1,   21.1,   23.2,   26.4,   28.8,   25.6],\n        [1895. ,   26.9,   27.7,   31.2,   26.3,   22.8,   21.3,   20.5,\n           21.2,   21.4,   24.1,   28.1,   26.8,   24.9],\n        [1896. ,   30.9,   30.5,   26.4,   24.7,   23.2,   21.7,   18.6,\n           20.4,   22.3,   22.5,   23.9,   25.3,   24.2],\n        [1897. ,   28.2,   27.9,   26.2,   26.7,   23.3,   21.1,   22.2,\n           21.6,   21.9,   22.8,   26.4,   30.8,   24.9],\n        [1898. ,   27.6,   30.7,   31.2,   26.2,   24.3,   19.6,   21.6,\n           20.7,   22.3,   22.3,   25.7,   27. ,   24.9],\n        [1899. ,   29.5,   27.7,   28.5,   24.8,   23.2,   20.1,   20. ,\n           20.4,   21.7,   22.3,   23.1,   27.8,   24.1],\n        [1900. ,   30.5,   30.2,   26.9,   24.7,   22.2,   20.6,   19.4,\n           19.3,   21.7,   23.7,   24.6,   26.2,   24.2],\n        [1901. ,   27.2,   29.9,   30.3,   26.7,   23.2,   20.9,   20.2,\n           20.3,   21.4,   22.8,   24.9,   24.8,   24.4],\n        [1902. ,   26.6,   26.3,   30.2,   25.6,   23.4,   21. ,   19.8,\n           22.2,   21.9,   22. ,   25.4,   25.1,   24.1],\n        [1903. ,   29.5,   31.6,   26.5,   24.6,   24.2,   21.6,   19.5,\n           19.7,   20.3,   22.7,   24.8,   29. ,   24.5],\n        [1904. ,   32.1,   29.9,   31.8,   26.7,   21.7,   20.9,   19.5,\n           21.1,   20.9,   23.2,   24.5,   27.1,   24.9],\n        [1905. ,   26.3,   30.3,   27.7,   26.9,   23.2,   21.2,   20.4,\n           20.4,   22.2,   23.9,   24.2,   26.9,   24.5],\n        [1906. ,   28.4,   25.9,   29.3,   28.3,   23.5,   21.4,   19.1,\n           20.2,   20.1,   23.8,   24.6,   29.2,   24.5],\n        [1907. ,   32.3,   30.5,   29.4,   27.9,   24.6,   21.2,   20.3,\n           21. ,   21.2,   22.1,   24.4,   26.5,   25.1],\n        [1908. ,   28.9,   29.7,   27.9,   26.8,   22.7,   19.2,   20.2,\n           20.4,   22.2,   23.5,   24.9,   26.7,   24.4],\n        [1909. ,   30.7,   32.3,   28.2,   26.7,   23.2,   21.2,   19.8,\n           20.3,   22.1,   21.8,   24.1,   31.6,   25.2],\n        [1910. ,   28.5,   31.8,   31.5,   28.1,   22.1,   20.4,   18.7,\n           20.6,   21.7,   21.7,   24.5,   26.8,   24.7],\n        [1911. ,   28.5,   31.5,   28.1,   26.9,   22.8,   20.6,   20.3,\n           19.9,   21.3,   24.6,   23.9,   24.1,   24.4],\n        [1912. ,   27.2,   29.8,   26.8,   26.8,   22.7,   22.3,   19.9,\n           21.4,   20.5,   22.2,   26.5,   27.1,   24.4],\n        [1913. ,   28.8,   29.8,   28.5,   26. ,   26.1,   22.7,   20.4,\n           19.9,   22.7,   22.5,   24.7,   25.3,   24.8],\n        [1914. ,   29.4,   28.5,   28.1,   23.9,   22.5,   21.8,   19.8,\n           22.9,   24.8,   25. ,   25.1,   27.3,   24.9],\n        [1915. ,   30.2,   29. ,   28.9,   28.2,   24.4,   21.9,   20.3,\n           20.8,   19.9,   22.5,   27.8,   30.4,   25.4],\n        [1916. ,   26.9,   28.1,   26.9,   28.6,   23.5,   20. ,   19.1,\n           19.8,   24.1,   22.6,   26.4,   28.5,   24.5],\n        [1917. ,   29.2,   30.6,   26. ,   26.8,   22.2,   20.7,   19.5,\n           19.5,   20. ,   23.4,   26.2,   27.3,   24.3],\n        [1918. ,   32.5,   29.8,   29.4,   27.9,   23.6,   21.5,   20.9,\n           20.1,   22.4,   22.8,   25.8,   27.7,   25.4],\n        [1919. ,   27. ,   29. ,   29.1,   27. ,   24.6,   21.3,   21.3,\n           20.4,   21.8,   22.4,   25. ,   25.3,   24.5],\n        [1920. ,   32. ,   29.4,   28.1,   28.9,   23.1,   20.4,   19.4,\n           18.5,   22.3,   23.8,   26.6,   28. ,   25. ],\n        [1921. ,   30.7,   33. ,   31.5,   27.8,   22.6,   21.6,   20.7,\n           21.7,   21.8,   23.5,   25. ,   28.3,   25.7],\n        [1922. ,   28.2,   30.1,   30.1,   26.2,   22.9,   20.3,   19.3,\n           20.7,   21.4,   24.2,   25.8,   25.4,   24.5],\n        [1923. ,   28.1,   29.7,   29.8,   27.5,   23.3,   19.9,   19.9,\n           20.9,   20.2,   22.6,   26. ,   26.6,   24.5],\n        [1924. ,   28.6,   30.3,   28. ,   29.4,   24.1,   21.3,   21.2,\n           20.2,   22. ,   21.6,   25.5,   30.3,   25.2],\n        [1925. ,   29. ,   28.9,   28.9,   25.7,   22.8,   21.7,   19.4,\n           21.2,   22.4,   21.6,   28.3,   27.1,   24.8],\n        [1926. ,   30.6,   26.7,   28.9,   24.4,   23.4,   20.9,   19.7,\n           19.4,   22.2,   23.1,   26.4,   30.3,   24.7],\n        [1927. ,   29.1,   28.8,   26.4,   29. ,   23.9,   20.1,   19.2,\n           20.4,   22.8,   23.9,   25.5,   31.1,   25. ],\n        [1928. ,   29.5,   29.8,   27.8,   26. ,   24.2,   21.4,   19.8,\n           20.6,   20.8,   21.5,   25.4,   26.6,   24.5],\n        [1929. ,   30.4,   29. ,   29.7,   25.9,   22.4,   20. ,   18.7,\n           19.9,   21.6,   22.7,   23.5,   27.8,   24.3],\n        [1930. ,   28.1,   27.3,   29.9,   26.4,   23.8,   21.4,   20. ,\n           20.5,   22.5,   23.1,   25. ,   26.7,   24.6],\n        [1931. ,   31.2,   27.9,   29.8,   26. ,   21.2,   18.8,   19.4,\n           19.9,   20.2,   24.6,   27.9,   31.5,   24.9],\n        [1932. ,   29.4,   31.1,   28.8,   26.2,   24.5,   20.8,   20. ,\n           19.4,   21.3,   24.1,   25.3,   27.7,   24.9],\n        [1933. ,   29.5,   30.9,   28.8,   28.6,   23.2,   21.4,   19.5,\n           20.8,   22.5,   23.2,   29.1,   29.3,   25.6],\n        [1934. ,   30.2,   30.9,   29.7,   25.6,   25.3,   19.8,   19. ,\n           20.9,   21.1,   22.2,   26. ,   27.3,   24.8],\n        [1935. ,   29.2,   29.9,   28.6,   26.9,   23.5,   20.3,   19.4,\n           20.1,   19.9,   22.1,   23.5,   26.6,   24.2],\n        [1936. ,   28.3,   28.9,   29.3,   27.5,   22.6,   20.7,   19.3,\n           21. ,   24.2,   22.6,   25.9,   27.4,   24.8],\n        [1937. ,   28.5,   28.1,   28.1,   28.5,   23.1,   21.5,   20.7,\n           20.4,   21.1,   23.4,   25.7,   26. ,   24.6],\n        [1938. ,   29.8,   27.7,   27.6,   25.6,   23.6,   20.5,   20.2,\n           20.6,   23.4,   22.9,   24.7,   26.8,   24.4],\n        [1939. ,   26. ,   30.4,   30.3,   26.6,   22.8,   21.1,   19.1,\n           19.8,   22.6,   23.3,   26.4,   28.1,   24.7],\n        [1940. ,   29.3,   32.4,   27.6,   26.5,   24. ,   22.9,   20.4,\n           21.8,   22.9,   22.3,   26.6,   26.4,   25.3],\n        [1941. ,   29.9,   29.1,   27.7,   25. ,   25.5,   21. ,   20.7,\n           21.6,   21.3,   23.6,   24.8,   29. ,   24.9],\n        [1943. ,   27.1,   29. ,   28.6,   26.2,   24. ,   21.2,   19.1,\n           20.4,   21.5,   22.3,   26.8,   27.5,   24.5],\n        [1944. ,   27.2,   28.9,   28. ,   26.5,   22.7,   22.3,   20.6,\n           20.8,   21.7,   25.3,   27.5,   26.8,   24.9],\n        [1945. ,   30.1,   31.2,   29.1,   28. ,   24.2,   21.6,   19.6,\n           19.9,   21. ,   24.4,   27.1,   26.9,   25.3],\n        [1946. ,   27.2,   29.3,   28.2,   27.4,   23.2,   20.6,   19.2,\n           20.1,   22.5,   24.5,   24.6,   26. ,   24.4],\n        [1947. ,   26.9,   29. ,   30.4,   26.1,   23.1,   21.8,   19.8,\n           20.4,   21.7,   23.9,   24.1,   25.6,   24.4],\n        [1948. ,   28.7,   30.1,   32.2,   26.3,   25.4,   22.3,   19.6,\n           22.1,   22.1,   23.8,   24.7,   25.7,   25.3],\n        [1949. ,   30.6,   30.6,   30.5,   28.1,   24. ,   22.7,   21.5,\n           21.8,   22.4,   22.3,   26.8,   27.5,   25.7],\n        [1950. ,   31.9,   30.8,   30.2,   28.5,   22.8,   21.5,   20.5,\n           21.5,   22. ,   22.2,   25.1,   26.6,   25.3],\n        [1951. ,   26.6,   29.3,   29.5,   26.6,   23. ,   20.2,   18.6,\n           19.7,   22.2,   23.5,   24.4,   26.4,   24.2],\n        [1952. ,   29.3,   31.5,   30.6,   29. ,   22.8,   22. ,   19.5,\n           20.8,   21.9,   23.6,   23.8,   27.7,   25.2]]),\n array([[1945. ,   31.5,   32.1, ...,   25.8,   28.4,   24.4],\n        [1946. ,   28.2,   29.8, ...,   24.4,   27.4,   23.6],\n        [1947. ,   29.6,   32. , ...,   24.9,   26. ,   23.7],\n        ...,\n        [2019. ,   31.3,   32.2, ...,   29.8,   33.9,   26.1],\n        [2020. ,   31.6,   33. , ...,   25. ,   32.4,   25.7],\n        [2021. ,   33.6,   30.8, ...,   26.8,   32.5,   25.3]])]"},"exec_count":42,"output_type":"execute_result"}},"pos":62,"type":"cell"}
{"cell_type":"code","exec_count":43,"id":"7993e4","input":"(towns, tables) = get_temperatures(STATIONS)\nclean_tables = clean_all(tables)\nalbany = clean_all(tables)[towns.index(\"Albany\")]\nassert_equal(albany.shape, (103, 14))\nassert_true(np.allclose(albany[100], np.array([2019., 22.2, 22.2, 21.2, 21.2, 18.7, 17.6, 16.8, 17.9, 19.3, 19.3, 19.4, 23.5, 19.9])))\nprint(\"So far so good.\")\n","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"clean_all","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"So far so good.\n"}},"pos":63,"type":"cell"}
{"cell_type":"code","exec_count":44,"id":"da423a","input":"towns.index('Albany')","output":{"0":{"data":{"text/plain":"0"},"exec_count":44,"output_type":"execute_result"}},"pos":64,"type":"cell"}
{"cell_type":"code","exec_count":45,"id":"341736","input":"def get_clean(town):\n    (towns, table) = get_temperatures(STATIONS, quiet=True)\n    return table[towns.index(town)]\n\nget_clean('Albany')","output":{"0":{"data":{"text/plain":"array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n       [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n       [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n       ...,\n       [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n       [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7],\n       [2022. ,   22.4,   23.6, ...,    nan,    nan,    nan]])"},"exec_count":45,"output_type":"execute_result"}},"pos":66,"type":"cell"}
{"cell_type":"code","exec_count":46,"id":"bac8fc","input":"import matplotlib.pyplot as plt\nyear=get_clean('Albany')[:,0]\nannual_ave=get_clean('Albany')[:,-1]\nplt.plot(year,annual_ave)","output":{"0":{"data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7f6b90459b50>]"},"exec_count":46,"output_type":"execute_result"},"1":{"data":{"image/png":"d2a740a0bd0beb54b966947c71186ca383c4f308","text/plain":"<Figure size 864x504 with 1 Axes>"},"exec_count":46,"metadata":{"image/png":{"height":411,"width":713},"needs_background":"light"},"output_type":"execute_result"}},"pos":68,"type":"cell"}
{"cell_type":"code","exec_count":47,"id":"a0ad56","input":" (towns, table) = get_temperatures(STATIONS, quiet=True)","pos":74,"type":"cell"}
{"cell_type":"code","exec_count":48,"id":"b6c00d","input":"def get_table(town):\n    (towns, tables) = get_temperatures(STATIONS, quiet=True)\n    return tables[towns.index(town)]\nget_table('Albany')","output":{"0":{"data":{"text/plain":"array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n       [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n       [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n       ...,\n       [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n       [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7],\n       [2022. ,   22.4,   23.6, ...,    nan,    nan,    nan]])"},"exec_count":48,"output_type":"execute_result"}},"pos":75,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"c7e968","input":"def year_range(town):\n    town_data=np.genfromtxt(fname=temperature_file(town),delimiter=',',skip_header=1,usecols=range(2,16))\n    year_town=int(town_data[0,0]),int(town_data[-1,0])\n    return year_town\n\nyear_range('Albany')","output":{"0":{"data":{"text/plain":"(1880, 2022)"},"exec_count":5,"output_type":"execute_result"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":52,"id":"4c4f44","input":"def hot_years (town):\n    #correctdata_mask=np.isclose(get_ave,get_town(town)[:,-1]) #compare average\n    #complete_data=get_town(town)[correctdata_mask] #remove false data row ( with years and average (full data))\n\n    average_mask=[False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n    overall_average=np.nanmean(get_town(town)[:,average_mask]) #ave of all average,axis=0,ignore nan\n\n    new_mask=get_table(town)[:,-1]>overall_average\n    hottest_years=get_table(town)[new_mask][:,[0,-1]]\n    return(overall_average,hottest_years)\n\n","metadata":{"deletable":false,"nbgrader":{"checksum":"dc859de1bda27619c27aa29eddf795d4","grade":false,"grade_id":"4c4f44","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":36,"type":"cell"}
{"cell_type":"code","exec_count":55,"id":"a9977c","input":"def validate_averages():\n    #read temp data for all town in STATIONS\n    towns,tables=get_temperatures(STATIONS,quiet=True)\n    each_town=[]\n    answer=[]\n    #return nx3 array 3column(year, reported mean, and calculated mean)\n    for town in towns:\n        #print(towns.index(town)) get index for each town\n        calculated_average=np.round(np.mean(get_table(town)[:,1:-1],axis=1),1)  #round to 1 decimal place\n        falsedata_mask=np.logical_not(np.isclose(calculated_average,get_table(town)[:,-1])) #compare average and assign true to uncorrect mean's row\n        falsedata=get_table(town)[falsedata_mask] #get false data row ( with years and average (full data))\n        year,reported_mean,calculated_mean=(falsedata[:,0],falsedata[:,-1],calculated_average[falsedata_mask])\n        full_data=np.transpose((year,reported_mean,calculated_mean))\n        each_town.append(full_data)\n    answer=np.vstack(each_town)\n    return answer\n\n\n","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"0547b495a7f24b6e5840b214b917b83f","grade":false,"grade_id":"a9977c","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":51,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":56,"id":"8c953c","input":"answer = validate_averages()\nassert_equal(answer[0,0], 1905.)\nassert_equal(answer[10,0], 1939.)\nassert_equal(answer[11,2], 32.6)\nassert_equal(np.all(np.equal(np.isnan(answer[3]), np.array([False, True, True]))), True)\nprint(\"So far, so good. You should do additional testing.\")\n","metadata":{"deletable":false,"editable":false,"nbgrader":{"grade":true,"grade_id":"validate_averages","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","output_type":"stream","text":"So far, so good. You should do additional testing.\n"}},"pos":52,"type":"cell"}
{"cell_type":"code","exec_count":57,"id":"b82201","input":"def missing_years (table):\n    #return an array of years(int) than fall within range of year(from uncleaned table)\n    fullyear=np.arange(table[0,0],table[-1,0]+1,dtype=int)\n\n    #use the cleaned table to get an array of the years that have valid data\n    #keep row that dont have null value for annual average\n    remove_nullmask=np.logical_not(np.isnan(table[:,-1]))\n    get_row=table[remove_nullmask]\n    #print(get_row)\n\n    #keeps rows that have a calculated mean temperature within 0.15 of the reported annual average\n    calculated_average=np.mean(get_row[:,1:-1],axis=1)\n    validtemp_mask=np.isclose(calculated_average,get_row[:,-1],rtol=0.15)\n\n    get_validyear=get_row[validtemp_mask][:,0].astype('int32')\n    #print(get_validyear)\n\n    get_index=get_validyear[:]-fullyear[0]\n    print(get_index)\n\n    #get_index=np.where(fullyear==get_validyear[:,None])[1] #indices of the valid years in the full range of years\n    #print(fullyear[get_index])\n\n    #generate a boolean mask over the full range of years that selects the non-valid years\n    #make true to non valid years\n    #invalid = np.ones(fullyear.size, dtype = bool)\n    #invalid[get_index] = False\n    #result = fullyear[invalid]\n    #return result\n\n    arr_bool=np.full(fullyear.size,True,dtype=bool) #create full year boolean array\n    arr_bool[get_index]=False #let all valid data be false, we want wrong data to be true\n    result=fullyear[arr_bool]\n    return result\n\n","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"603264e46b03b29bc87b840a53143572","grade":false,"grade_id":"b82201","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":76,"type":"cell"}
{"cell_type":"code","exec_count":58,"id":"1dcfb7","input":"x=[1,2,3,4,5] \ny=[3,4] #index2,3 #index3,4 #index1,2 clean\n","pos":77,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"90fac0","input":"#iterate through dictionaries\ndef get_temps():\n    new_stations=sorted(STATIONS)\n    for station in new_stations:\n        tem_arr=np.genfromtxt(fname=temperature_file(station),delimiter=',',skip_header=1,usecols=range(2,16))\n        tem_year=year_range(station)\n        output=\"Collecting data for {:<10} : {} years recorded between {} and {}\".format(station,len(tem_arr),tem_year[0],tem_year[1])\n\n        print(output)\n\n\nget_temps()","output":{"0":{"name":"stdout","output_type":"stream","text":"Collecting data for Albany     : 107 years recorded between 1880 and 2022\nCollecting data for Broome     : 84 years recorded between 1939 and 2022\nCollecting data for Geraldton  : 73 years recorded between 1880 and 1953\nCollecting data for Perth      : 79 years recorded between 1944 and 2022\n"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"5d9a34","input":"def get_temperatures(stations, quiet=True):\n    towns=sorted(stations)\n    tables=[]\n    for x in towns:\n        tem_arr=np.genfromtxt(fname=temperature_file(x),skip_header=1,delimiter=\",\",usecols=range(2,16))\n        tables.append(tem_arr)\n\n    if quiet:\n        return(towns,tables);\n\n    else:\n        get_temps()\n        return(towns,tables)\n\n\nget_temperatures(STATIONS, quiet=True)","output":{"0":{"data":{"text/plain":"(['Albany', 'Broome', 'Geraldton', 'Perth'],\n [array([[1880. ,   22.1,   22.8, ...,   18. ,   20.8,   18.2],\n         [1881. ,   20.1,   22.2, ...,   18.7,   20.7,   18.2],\n         [1882. ,   20.2,   22.1, ...,   17.8,   20.8,   17.8],\n         ...,\n         [2020. ,   22.2,   23.4, ...,   20.5,   21.1,   20.1],\n         [2021. ,   22.8,   21.9, ...,   18.8,   21.3,   19.7],\n         [2022. ,   22.4,   23.6, ...,    nan,    nan,    nan]]),\n  array([[1939. ,    nan,    nan, ...,   33. ,   34.7,    nan],\n         [1940. ,   31.8,   33.1, ...,   35.4,   34.4,   32.3],\n         [1941. ,   33.5,   34.9, ...,   33.2,   34.7,   31.8],\n         ...,\n         [2020. ,   33.3,   33.7, ...,   34.6,   33.3,   32.9],\n         [2021. ,   35. ,   33.1, ...,   34.7,   34.6,   32.9],\n         [2022. ,   33.7,   34.3, ...,    nan,    nan,    nan]]),\n  array([[1880. ,   31.3,   26.8, ...,   23.7,   25.6,   23.2],\n         [1881. ,   26.9,   28.9, ...,   24.4,   28.9,   24.1],\n         [1882. ,   26.6,   28.8, ...,   23.6,   26.3,   22.6],\n         ...,\n         [1951. ,   26.6,   29.3, ...,   24.4,   26.4,   24.2],\n         [1952. ,   29.3,   31.5, ...,   23.8,   27.7,   25.2],\n         [1953. ,   31. ,   29.1, ...,    nan,    nan,    nan]]),\n  array([[1944. ,    nan,    nan, ...,   26.8,   25.5,    nan],\n         [1945. ,   31.5,   32.1, ...,   25.8,   28.4,   24.4],\n         [1946. ,   28.2,   29.8, ...,   24.4,   27.4,   23.6],\n         ...,\n         [2020. ,   31.6,   33. , ...,   25. ,   32.4,   25.7],\n         [2021. ,   33.6,   30.8, ...,   26.8,   32.5,   25.3],\n         [2022. ,   34.6,   35.1, ...,    nan,    nan,    nan]])])"},"exec_count":7,"output_type":"execute_result"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"009633","input":"def get_town(town):\n    townfulldata=np.genfromtxt(fname=temperature_file(town),delimiter=',',skip_header=1,usecols=range(2,16))\n    return(townfulldata)\n\nget_town('Albany')[0]\n","output":{"0":{"data":{"text/plain":"array([1880. ,   22.1,   22.8,   20.6,   19.2,   17.5,   14.7,   15.1,\n         15.2,   16.2,   16.2,   18. ,   20.8,   18.2])"},"exec_count":8,"output_type":"execute_result"}},"pos":11,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"fdf579","input":"def get_table(town):\n    townfulldata=np.genfromtxt(fname=temperature_file(town),delimiter=',',skip_header=1,usecols=range(2,16))\n    return(townfulldata)","pos":12,"type":"cell"}
{"cell_type":"markdown","id":"053a6f","input":"#### Q5. Augmenting with `nan` [1 lab mark]\n\n* Write a function `augmented(table)` that returns a pair of arrays:\n  * the first is an array of all the years in the range of years covered in the table, as integers\n  * the second is an array of floats which contains:\n    * the reported annual average for the corresponding year\n    * `np.nan` where either the data was null or missing\n\nAgain the function should have no loops.\n\n_Hint:_ Use a similar structure to `missing_years`.\n\nAgain, check you are getting the right results on the downloaded tables.\n\n","pos":81,"type":"cell"}
{"cell_type":"markdown","id":"29469e","input":"* Print the results of running `validate_averages()` for all the stations. What do you observe?\n* Use a list comprehension to count the number of rows returned by `'validate_averages()` that do not have a missing reported average. (This will be useful for checking your code later on.)","pos":53,"type":"cell"}
{"cell_type":"markdown","id":"391f17","input":"You will notice that the plot has not treated missing data well. Rather than a line joining the missing data, it would be more instructive to have a gap. (Our plot of the cleaned data will also not include the final year in the x-axis.)\n\nOne way to leave gaps is to ensure all missing years are set to `nan`. Matplotlib will not plot these years by default.\n\n* To demonstrate this, plot the _uncleaned_ data for Albany.\n\n","pos":69,"type":"cell"}
{"cell_type":"markdown","id":"4053f9","input":"#### Masking out the 'bad' data\n\n* Use the boolean array from above as a mask to select all the rows in the Albany data where the averages don't match. (1 line of code)\n* Change your line of code from above so that it prints just the year for each of the rows that don't match.\n\n_Hint: You can combine selection using a boolean array with the other kinds of selection._\n\n","pos":27,"type":"cell"}
{"cell_type":"markdown","id":"415214","input":"### Data precision and cleaning policy\n\nFrom the results of our `validate_averages()` function, we can see that our mismatches in the averages are two types: missing data, and values that are out by one decimal place (1dp). Of course there may be data for other stations that we have't checked that are out by more than this.\n\n* _For the numbers that differ by one decimal place, which do anticipate is more accurate, and why?_\n\nThe averages that we have calculated are based on the monthly numbers, which are already rounded to 1dp (presumably for human consumption). In summing these numbers to get the average, the \"errors\" or lack of precision from rounding, is accumulated. If the positive and negative errors are roughly equal, they may tend to cancel each other out (as has happened in the majority of cases in our data). Where this does not occur we may see them build up to the point that they affect the precision we are seeing (in this case to 1dp).\n\nIn the case of the reported averages, it seems reasonable to assume that more precise monthly figures were used in the calculations, and the rounding to 1dp only occurred at the end of the calculation. These results are therefore likely to be more reliable.\n\nIn general, it is good practice to *delay rounding until as late as possible* to avoid compounding rounding errors.\n\nOf course, all of this assumes that the sensors used to read the temperature data are sufficiently accurate. If not, the differences will be within the realm of \"_noise_\". Nevertheless it seems reasonable to assume that the reported averages are _not worse_ than our calculated averages, for the above reasons.\n\nIn respect of the missing data, we can see (at least for these data) that the years with reported null values correspond to those that we were also not able to calculate due to missing monthly data. It seems reasonable to assume that missing values in the reported averages column reflect issues in the recorded data.\n\nFinally, we need to consider floating point precision. We know that the floating point representation of the two means may be slightly smaller or larger than the number reported to 1dp. We might therefore choose to accept a _tolerance_ between calculated and reported means.\n\nOur results for `validate_averages()` suggest that a tolerance of around 0.1 seems reasonable. Note however that we are comparing rounded calculated averages with the reported averages. The raw calculated averages may therefore be up to +/-0.05 different to those we listed. In some ways rounding to 1dp and then using `islcose()` is a little artificial, since `isclose()` introduces a tolerance that (by default) is smaller than variance obtained by rounding. (Remember the philosophy of delaying rounding as long as possible.)\n\nUltimately, we cannot get around the fact that we must \"choose our poison\", and set a somewhat arbitrary cut-off. Based on our inspection from `validate_averages()`, which included a potential rounding error up to 0.05, we will set our tolerance at 0.15. (You might like to experiment with different tolerances and see how they affect the results.)\n\nWe will therefore proceed with the follow **data cleaning policy**:\n\n1. If the calculated mean is within 0.15 of the reported annual average, we'll assume the data are valid.\n2. Since the reported averages may have been calculated on more precise figures and reported to 1 decimal place, we will use the reported average when considering annual figures.\n3. We will remove years where the annual figure is a null value.\n\n","pos":54,"type":"cell"}
{"cell_type":"markdown","id":"451928","input":"* Using the table for Albany, plot the annual averages (last column) against the years (first column) for the _cleaned_ data.\n\n","pos":67,"type":"cell"}
{"cell_type":"markdown","id":"58b354","input":"### Stacks of arrays\n\nAnother way of extracting columns is to `stack` them in a new array. Look up the API for `numpy.stack()`.\n\nReturning to our years where the calculated average doesn't match the listed average, assuming `mismatch` is my boolean mask, I can combine this with index selection and `stack` to say:\n\n```\nprint(np.stack((albany[mismatch,0], albany[mismatch,13])))\n\n[[1905.  1920.  1929.  1938.  1948.  1965.  2002.  2008.  2016.  2020. ]\n [  18.9   20.6   18.9    nan   19.9    nan    nan   19.5   19.4    nan]]\n```\n\n- Give this a try.\n\nThis has taken each column of data as a 1-d (flattened) array and stacked them to create a 2-d array.\n\nGiven our data are extracted from the columns of a \"table\", its more natural to keep them as vertical arrays. If we want to see them vertically again, we can _transpose_ the stacked array. Give this a try:\n\n```\nprint(np.transpose(np.stack((albany[mismatch,0], albany[mismatch,13]))))\n```\n\nThe `T` operator can also be used as shorthand:\n\n```\nprint(np.stack((albany[mismatch,0], albany[mismatch,13])).T)\n```\n\nWhile this is perhaps less efficient than the earlier approach, since it creates a new array, its also more versatile. We can include other data in the new array, such as our calculated means.\n\n* Using this approach (stacking the three together), create an array that has the year, reported average, and calculated mean, for each year where the reported and calculated averages don't match. You should end up with a 10x3 array.\n\nYour output should start like this:\n\n```\n[[1905.    18.9   19. ]\n [1920.    20.6   20.7]\n [1929.    18.9   18.8]\n [1938.     nan    nan]\n...\n```\n\nCould all of your differences be explained by rounding or precision errors and missing data?\n\n","pos":38,"type":"cell"}
{"cell_type":"markdown","id":"5b47b4","input":"### Verifying the data\n\nLet's start with the first year of data.\n\n","pos":13,"type":"cell"}
{"cell_type":"markdown","id":"6cd2fc","input":"### Augmenting the data\n\nMatplotlib 'does its best' to anticpate what we want to see, and does a pretty good job in general! After all, it filled in all the years on the x-axis for us (allowing us to be a bit lazy), even though we only fed it x values for some of the years.\n\nBut it can only do so much. We will need to do it properly.\n\nWe will now 'augment' the data by including all of the years ranging from the first to the last year in the data. We will set the missing years to `np.nan` so that they are not plotted.\n\nWe can do all of this in numpy without using any loops.\n\n","pos":72,"type":"cell"}
{"cell_type":"markdown","id":"739476","input":"#### Q2. Putting it all together [1 lab mark]\n\nWrite a function `validate_averages()` that:\n\n* reads the temperature data for all towns specified in the `STATIONS` dictionary in alphabetical order of town name (using `get_temperatures()`)\n* returns an $n$ x 3 array which has one line for each of the $n$ cases in which the recorded annual average does not reconcile with the calculated average, the three columns being year, reported mean, and calculated mean\n\nNote that:\n\n* the array should be ordered (vertically) by town and then by year (although there is no label for the towns, it is just numbers)\n* `nan` is considered as not matching any number (including `nan`)\n* calculated means should be rounded to 1 decimal place\n* comparison of floats should use `np.islcose()` or related methods\n* you should not assume STATIONS will always be the same in future - there could be fewer or more towns (but the format will be the same)\n\n(This should only take about 8 lines of code, without being overly terse.)\n\n","pos":48,"type":"cell"}
{"cell_type":"markdown","id":"746ab3","input":"#### Applying a tolerance\n\nWe could apply a tolerance \"manually\" by subtracting, taking the absolute value and comparing with 1.5. However we can also use `np.isclose()`. `isclose()` allows us to set an absolute tolerance and a relative tolerance.\n\n* Read the documentation to see how the two parameters interact in determining what is defined as \"close\".\n* Try an alternative function `validate_averages_close()` and see if you get the same results.\n","pos":55,"type":"cell"}
{"cell_type":"markdown","id":"7602be","input":"Let's try doing this on all the years (the whole 2-D array) in \"one go\".\n\nComplete the following without using any loops. (Each should take 1 line to do the operation, and one line to check the shape where relevant.)\n\n* Select all of the monthly temperature data into an array (that is, all columns except the year and the average). Check the shape is as you would expect.\n* Use `ndarray.mean()` or `numpy.mean()` with the `axis` argument to get an array of the means for all years, rounded to 1 decimal place. Check the shape (to ensure you used the right axis).\n\n* Create a boolean array called `mismatch` of all those years where the stated annual average is not equal to your calculated average. Check the shape.\n* If you used `!=` above, try with `np.not_equal()` and with `np.isclose()`.\n* Use numpy's `any()` to check whether there are any that are different.\n\n","pos":18,"type":"cell"}
{"cell_type":"markdown","id":"764d79","input":"* Copy in the following functions, along with your data directories, from the lab _Heat1_\n  * `temperature_file(town)` from Q1\n  * `year_range(town)` from Q2\n  * `get_temperatures (stations, quiet=True)` from Q3\n\n","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"7917f0","input":"At first sight this appears to have solved our problem! We can just use the uncleaned data.\n\nBut actually this is just a coincidence of our specific data, not a general solution.\n\nHave a look at the data file for Albany. It happens that the gap of missing data from 1966 to 2001 has a null value either side. This causes matplotlib to not put a line between those values.\n\nTo demonstrate this, we can leave some other gaps without null values. A quick way to do this is by plotting every tenth value.\n\n```\ntable = get_table(\"Albany\",STATIONS)\nplt.plot(table[::10,0], table[::10,-1])\nplt.show()\n```\n\n* Generate this plot. What do you see?\n\n","pos":71,"type":"cell"}
{"cell_type":"markdown","id":"7dec4b","input":"<h3>Lab 8</h3>\n\n# Feel the Heat! Part 2\n\n<div>\n    <img src=\"summer_fan.gif\" width=300><br>\n</div>\n\n<small>Source: [Canadian Red Cross](https://www.redcross.ca/blog/2010/5/are-you-feeling-the-heat)</small>\n\nThe spring is getting hotter, and so are our array skills!\n\nIn this lab, we will continue our examination of the raw data from the Bureau of Meteorology on maximum temperatures for Western Australian towns. This is another longer more challenging lab, and you should attempt all the questions you can.\n","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"90f985","input":"* Repeat the above using `np.isclose()` rather than equality.\n\n","pos":16,"type":"cell"}
{"cell_type":"markdown","id":"95aead","input":"* Using `np.mean()` and array selection, determine whether the mean of the first 12 months maximum temperatures is equal to the average annual maximum reported for Albany in the last column of the table (1 line of code).","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"9c7362","input":"&copy; Cara MacNish","pos":87,"type":"cell"}
{"cell_type":"markdown","id":"9f58da","input":"* Plot the augmented table for Albany. Is it whate you expected?","pos":84,"type":"cell"}
{"cell_type":"markdown","id":"a3836b","input":"## Data Acquisition\n\nOnce again we will source our data from the Australian Government's **Bureau of Meteorology (BOM)** *Climate Data Online* service.\n","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"a3cf7e","input":"As a 2-D example, if we want the columns for January and April, we could use `albany[:,[1,4]]`. \n\n* Give this a try. Use selection again on the output to print only the first 5 rows.\n\nYou can also mix the use of boolean masks (such as `mismatch` from above) with the use of integer (or index) arrays.\n\n* Print the year and annual average columns for the mismatched years using an integer array to select the columns.\n  * See if you can do this at least two different ways.\n\nYou should get the same output you got with the boolean mask.","pos":33,"type":"cell"}
{"cell_type":"markdown","id":"b25995","input":"#### Q1. Selecting the hottest years [1 lab mark]\n\nWrite a function `hot_years(town)` that contains _no loops_, and has as its output a pair `(overall_average, hottest_years)` where:\n\n* `overall_average` is the average of all the averages (that is, the last column) ignoring nans.\n* `hottest_years` is an array containing the year and average, for each year where the average is hotter than the overall average.\n\nHow many years are hotter than the overall average? Is it about what you would expect?","pos":34,"type":"cell"}
{"cell_type":"markdown","id":"b5fc26","input":"#### Cleaning the table\n\n* Write a function `clean(table)` that takes a 14 column table, as returned by `get_temperatures()` and cleans it according to the above data cleaning policy.\n\nTips: To avoid a warning caused by nan's, it is suggested you _remove the nan rows first_.\n\nTherefore, it is suggested you (in 4 lines of code):\n\n1. make a mask that keeps all the rows that don't have a null value for annual average temperature (_hint: do not use equality - rather look for numpy methods to help you do this_)\n2. mask out those rows\n3. make a mask that keeps all the rows that have a calculated mean temperature within 0.15 of the reported annual average\n4. mask out those rows\n\n","pos":57,"type":"cell"}
{"cell_type":"markdown","id":"cae05b","input":"## Data Cleaning and Conversion\n\nDefine a convenience function `get_town(town)` that returns the \"table\" (numerical data) for `town`.\n\nFor example:\n\n```\nget_table(\"Albany\")[0]\n\n[1880.    22.1   22.8   20.6   19.2   17.5   14.7   15.1   15.2   16.2\n   16.2   18.    20.8   18.2]\n```\n\n","pos":10,"type":"cell"}
{"cell_type":"markdown","id":"cb0d25","input":"#### Q4 (Challenge). Identifying missing years [1 lab mark]\n\nWrite a method `missing_years(table)` that takes an uncleaned table, and returns an array of years (as integers) that fall within the range of years from the first in the table to the last in the table, that either:\n\n* don't have a reported annual average in the table\n* have a reported annual average of \"null\"\n\nYour method should not use any loops (or search methods, like `isin`). You can use previously defined methods.\n\n_Hint:_ It is suggested that you break it down into the following steps (about 9 lines of code):\n\n* use the information from the uncleaned table to generate an array of all the years in the range of your table\n* use the cleaned table to get an array of the years that have valid data\n* determine the indices of the valid years in the full range of years\n* generate a boolean mask over the full range of years that selects the non-valid years\n\n_Tip:_ You may also find the method `np.astype()` useful for converting to integers.\n\nCheck your results are correct by comparing (visually) with the downloaded tables.\n\n","pos":73,"type":"cell"}
{"cell_type":"markdown","id":"cdf9da","input":"#### `np.hstack`, `np.vstack` and `np.concatenate`\n\nStacking (and concatenating) can be used to create a bigger array in the same dimensions, or in a new dimension (as we did with `stack` above, where we stacked 1-D arrays to form a 2-D array).\n\nLet's say we have the years in three 1-d arrays and we want to put them in one long array. We can use `hstack` to stack them \"horizontally\":\n\n```\n(albany, broome, perth) = (tables[towns.index(\"Albany\")], tables[towns.index(\"Broome\")], tables[towns.index(\"Perth\")])\nall_years = np.hstack((albany[:,0], broome[:,0], perth[:,0]))\nprint(all_years.shape)\nprint(all_years)\n\n(315,)\n[1880. 1881. 1882. 1883. 1884. 1885. 1886. 1887. 1888. 1889. 1890. 1891.\n 1892. 1893. 1894. 1895. 1896. 1897. 1898. 1899. 1900. 1901. 1902. 1903.\n 1904. 1905. 1906. 1907. 1908. 1909. 1910. 1911. 1912. 1913. 1914. 1915.\n...\n```\n\n* Try this using `concatenate`.\n* Try using `vstack`. Does it work? What is the difference?\n\n","pos":42,"type":"cell"}
{"cell_type":"markdown","id":"d21706","input":"#### Q3. Cleaning all the data [1 lab mark]\n\n* Using your `clean(table)` function, write a function `clean_all(tables)` that takes a list of tables and returns a list of cleaned tables.","pos":61,"type":"cell"}
{"cell_type":"markdown","id":"d6f04e","input":"### Selecting with \"Index\" Arrays\n\nUsing a boolean array to select the columns in the above example is a bit unweildy. Luckily `numpy` allows integer \"masks\" (or arrays of indices) as well.\n\nAs a 1-D example, try the following which prints the temperatures for each quarter in the first year for Albany:\n\n```\nfirst_year = albany[0,:]         # select a 1-D array of the first year\nquarters = np.array([3,6,9,12])  # specify an array of indices for March, June, September, December\nprint(first_year[quarters])\n```\n\n","pos":31,"type":"cell"}
{"cell_type":"markdown","id":"da0a01","input":"Let's say we want to extract both the year and annual average columns from the temperature table. We could do that using boolean masks with something like this:\n\n```\nyear_and_av = [True, False, False, False, False, False, False, False, False, False, False, False, False, True]\nprint(albany[mismatch][:,year_and_av])\n```\n\n* Make sure you understand this construction, and then try it out. Print the shape of the resulting array.\n\nNote that `year_and_av` was automagically cast from a list to an array in this demonstration. Better would be to define `year_and_av` as an array.\n\n* Repeat this with `year_and_av` defined as an array.\n\n","pos":28,"type":"cell"}
{"cell_type":"markdown","id":"e5a39b","input":"## Visualisation\n\n* For convenience, define a \"helper\" function `get_clean (town)` that returns the cleaned temperature table for a named town.","pos":65,"type":"cell"}
{"cell_type":"markdown","id":"e9556a","input":"## Visualising the Complete Data!\n\nAt last its time to plot the historic temperatures. But because we've prepared well, if you've got this far this part is straightforward! It shouldn't take more than about 4 lines of code to get and plot the data for all the towns in `STATIONS` (plus a few lines to label the graph).\n\n* Plot all the historical data for average annual temperatures for all towns on a single chart.\n\nPart of the chart should look something like this (yours should include all four towns and all years):\n\n<div>\n    <img src=\"partial-graph.png\" width=600>\n</div>\n\nCan you see any trends? How might you quantify this?\n","pos":85,"type":"cell"}
{"id":0,"time":1666257843638,"type":"user"}
{"last_load":1666257823530,"type":"file"}